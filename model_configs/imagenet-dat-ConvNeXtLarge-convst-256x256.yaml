# Model Configuration for ImageNet dual-AT ConvNeXt-Large model with ConvStem

method: "dat"
dataset: imagenet
checkpoint: wandb/robust-ebms-2/wandb/run-20251030_060911-vjpuxho0/files/model_bestfid.pth
model_type: convnext_large
train_cmd: >
  python -m rebm.training.train
  experiments/imagenet/imagenet_indistonly_joint_convnext_300K.yaml
  model.model_type=convnext_large
  model.ckpt_path=checkpoints/convnext_large_cvst_robust.pt
  optimizer=adamw
  wd=0.05
  lr=0.001
  image_log.log_fid=true
  image_log.adaptive_steps=true
  image_log.num_steps=22
  image_log.sweep_radius=3
  AUC_th=0.2
  model.normalize_input=false
  data.image_size=256
  resume_from_state=wandb/robust-ebms-2/wandb/run-20251030_060911-vjpuxho0/files/training_state_latest.pth

# FID evaluation configuration
fid_eval_config: experiments/imagenet/imagenet_indistonly_joint_convnext_fid_50Ksamples_newopenimages.yaml
fid_num_steps: 24

# Robust accuracy evaluation configuration
pgd_epsilon: 3.0

# Training details
notes: |
  ConvNeXt-Large model with ConvStem for dual-AT training on ImageNet.
  Uses ConvBlock1 to replace PatchStem for improved robustness.

  IMPORTANT: This checkpoint expects [0,1] inputs WITHOUT ImageNet normalization.
  The model was trained with add_normalization=0, so normalize_input must be false.
  experiments/imagenet/imagenet_indistonly_joint_convnext_300K.yaml
